{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "Congratulations! You've been contracted by Hyundai Heavy Industries to help them build a predictive model for some ships. [Hyundai Heavy Industries](http://www.hyundai.eu/en) is one of the world's largest ship manufacturing companies and builds cruise liners.\n",
    "\n",
    "You've been flown to their headquarters in Ulsan, South Korea to help them give accurate estimates of how many crew members a ship will require.\n",
    "\n",
    "They are currently building new ships for some customers and want you to create a model and use it to predict how many crew members the ships will need.\n",
    "\n",
    "Here is what the data looks like so far:\n",
    "\n",
    "    Description: Measurements of ship size, capacity, crew, and age for 158 cruise\n",
    "    ships.\n",
    "\n",
    "\n",
    "    Variables/Columns\n",
    "    Ship Name     1-20\n",
    "    Cruise Line   21-40\n",
    "    Age (as of 2013)   46-48\n",
    "    Tonnage (1000s of tons)   50-56\n",
    "    passengers (100s)   58-64\n",
    "    Length (100s of feet)  66-72\n",
    "    Cabins  (100s)   74-80\n",
    "    Passenger Density   82-88\n",
    "    Crew  (100s)   90-96\n",
    "    \n",
    "It is saved in a csv file for you called \"cruise_ship_info.csv\". Your job is to create a regression model that will help predict how many crew members will be needed for future ships. The client also mentioned that they have found that particular cruise lines will differ in acceptable crew counts, so it is most likely an important feature to include in your analysis! \n",
    "\n",
    "Once you've created the model and tested it for a quick check on how well you can expect it to perform, make sure you take a look at why it performs so well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/dangkhoa/spark-2.3.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Linear_Regression').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ship_name: string (nullable = true)\n",
      " |-- Cruise_line: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tonnage: double (nullable = true)\n",
      " |-- passengers: double (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- cabins: double (nullable = true)\n",
      " |-- passenger_density: double (nullable = true)\n",
      " |-- crew: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = spark.read.csv(\"cruise_ship_info.csv\",inferSchema=True,header=True)\n",
    "\n",
    "raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
      "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
      "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+-----------------+\n",
      "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|Cruise_line_Index|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+-----------------+\n",
      "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|             16.0|\n",
      "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|             16.0|\n",
      "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|              1.0|\n",
      "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|              1.0|\n",
      "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|              1.0|\n",
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# String Indexer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(\n",
    "    inputCol=\"Cruise_line\",\n",
    "    outputCol=\"Cruise_line_Index\")\n",
    "\n",
    "string_indexed_data = indexer.fit(raw_data).transform(raw_data)\n",
    "string_indexed_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|      Cruise_line|count|\n",
      "+-----------------+-----+\n",
      "|            Costa|   11|\n",
      "|              P&O|    6|\n",
      "|           Cunard|    3|\n",
      "|Regent_Seven_Seas|    5|\n",
      "|              MSC|    8|\n",
      "|         Carnival|   22|\n",
      "|          Crystal|    2|\n",
      "|           Orient|    1|\n",
      "|         Princess|   17|\n",
      "|        Silversea|    4|\n",
      "|         Seabourn|    3|\n",
      "| Holland_American|   14|\n",
      "|         Windstar|    3|\n",
      "|           Disney|    2|\n",
      "|        Norwegian|   13|\n",
      "|          Oceania|    3|\n",
      "|          Azamara|    2|\n",
      "|        Celebrity|   10|\n",
      "|             Star|    6|\n",
      "|  Royal_Caribbean|   23|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string_indexed_data.groupBy('Cruise_line').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-------------------+-------------------+----------------------+\n",
      "|corr(crew, Cruise_line_Index)|    corr(crew, Age)|corr(crew, Tonnage)|corr(crew, passengers)|\n",
      "+-----------------------------+-------------------+-------------------+----------------------+\n",
      "|         -0.48332562728617057|-0.5306565039638852|  0.927568811544939|    0.9152341306065384|\n",
      "+-----------------------------+-------------------+-------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "string_indexed_data.select(\n",
    "    corr('crew','Cruise_line_Index'),\n",
    "    corr('crew','Age'),\n",
    "    corr('crew','Tonnage'),\n",
    "    corr('crew','passengers')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------------+------------------+\n",
      "|corr(crew, length)|corr(crew, passenger_density)|corr(crew, cabins)|\n",
      "+------------------+-----------------------------+------------------+\n",
      "|0.8958566271016579|         -0.15550928421699717|0.9508226063578497|\n",
      "+------------------+-----------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string_indexed_data.select(\n",
    "    corr('crew','length'),\n",
    "    corr('crew','passenger_density'),\n",
    "    corr('crew','cabins')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Assembler\n",
    "- Grab all columns -> 1 single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+------+------+--------------------+----+\n",
      "|           Tonnage|passengers|length|cabins|            features|crew|\n",
      "+------------------+----------+------+------+--------------------+----+\n",
      "|30.276999999999997|      6.94|  5.94|  3.55|[30.2769999999999...|3.55|\n",
      "|30.276999999999997|      6.94|  5.94|  3.55|[30.2769999999999...|3.55|\n",
      "|            47.262|     14.86|  7.22|  7.43|[47.262,14.86,7.2...| 6.7|\n",
      "|             110.0|     29.74|  9.53| 14.88|[110.0,29.74,9.53...|19.1|\n",
      "|           101.353|     26.42|  8.92| 13.21|[101.353,26.42,8....|10.0|\n",
      "+------------------+----------+------+------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Define assembler \n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Tonnage',\n",
    "               'passengers',\n",
    "               'length',\n",
    "               'cabins'],\n",
    "    outputCol='features')\n",
    "\n",
    "# transform\n",
    "vector_indexed_data = assembler.transform(string_indexed_data)\n",
    "vector_indexed_data \\\n",
    "    .select([\n",
    "        'Tonnage', 'passengers', 'length', 'cabins',\n",
    "        'features',\n",
    "        'crew']) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset - Train/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[30.2769999999999...|3.55|\n",
      "|[30.2769999999999...|3.55|\n",
      "|[47.262,14.86,7.2...| 6.7|\n",
      "|[110.0,29.74,9.53...|19.1|\n",
      "|[101.353,26.42,8....|10.0|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X = features, y = crew\n",
    "dataset = vector_indexed_data.select('features', 'crew')\n",
    "\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = dataset.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol='features',\n",
    "    labelCol='crew',\n",
    "    predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.01106238038784619,-0.1122675787110843,0.4303942062516852,0.7455807066020125]\n",
      "Intercept: -0.9781181495770807\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: {}\\nIntercept: {}\".format(model.coefficients,model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.073642564205559\n",
      "MSE: 1.1527083556738875\n",
      "R2: 0.8996652491789541\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = model.summary\n",
    "\n",
    "# train RMSE, MSE\n",
    "print(\"RMSE: {}\".format(trainingSummary.rootMeanSquaredError))\n",
    "print(\"MSE: {}\".format(trainingSummary.meanSquaredError))\n",
    "print(\"R2: {}\".format(trainingSummary.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6590121538629906\n",
      "MSE: 0.43429701893913797\n",
      "R2: 0.9685480407306172\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate(test_data)\n",
    "\n",
    "# test RMSE, MSE\n",
    "print(\"RMSE: {}\".format(test_results.rootMeanSquaredError))\n",
    "print(\"MSE: {}\".format(test_results.meanSquaredError))\n",
    "print(\"R2: {}\".format(test_results.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_data.select('features')\n",
    "\n",
    "predictions = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[3.341,0.66,2.79,...|0.4315861299702636|\n",
      "|[10.0,2.08,4.4,1.04]|1.5681275329558337|\n",
      "|[10.0,2.08,4.4,1.04]|1.5681275329558337|\n",
      "|[14.745,3.08,6.17...| 2.657850661683609|\n",
      "|[16.8,2.96,5.14,1...|2.1911034738585657|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|crew|\n",
      "+--------------------+----+\n",
      "|[3.341,0.66,2.79,...|0.59|\n",
      "|[10.0,2.08,4.4,1.04]| 1.6|\n",
      "|[10.0,2.08,4.4,1.04]| 1.6|\n",
      "|[14.745,3.08,6.17...| 1.8|\n",
      "|[16.8,2.96,5.14,1...|1.97|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Real label\n",
    "test_data.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
